{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gans.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8coLQ3KOu4cA","colab_type":"text"},"source":["# Generative Adversarial Networks\n","\n","Применение adversarial loss (более общей идеи, лежащей в основе GANов) позволило решить задачи, которые казались невозможными:\n","\n","* [Машинный перевод без параллельных данных](https://arxiv.org/pdf/1710.11041.pdf)\n","* [Циклоганы: перевод изображений в другой домен](https://arxiv.org/abs/1703.10593)\n","* Колоризация и [Super Resolution](https://arxiv.org/abs/1807.02758)\n","* [Генерация и морфинг произвольных данных](https://arxiv.org/pdf/1809.11096.pdf) ([тут](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/biggan_generation_with_tf_hub.ipynb#scrollTo=HuCO9tv3IKT2) можно поиграться с генерацией бургеров)\n","* Применения в борьбе с adversarial атаками\n","\n","Вот постоянно пополняющийся список приложений GANов: https://github.com/nashory/gans-awesome-applications\n","\n","Сама [статья](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf) Яна Гудфеллоу про GANы вышла в конце 2014 года и была процитирована 7687 раз за 4 года.\n","\n","\n","<img width='500px' src='https://cdn-images-1.medium.com/max/800/1*eWURQXT41pwHvDg1xDiEmw.png'>"]},{"cell_type":"markdown","metadata":{"id":"NZdtbv7Qu4cE","colab_type":"text"},"source":["Теперь немного формальных определений:\n","\n","* Пусть $z$ — это вектор из латентного пространства, насэмпленный из нормального распределения.\n","* $G(z)$ обозначает функцию генератора, которая отображает латентный вектор в пространство данных. Цель $G$ — оценить истинное распределение данных $p_d$, чтобы сэмплировать данные из оцененного распределения $p_g$.\n","* $D(G(z))$ это вероятность (число от 0 до 1), что выход генератора $G$ является реальным изображением.\n","\n","$D$ и $G$ играют в минимаксную игру, в которой $D$ старается максимизировать вероятность, что он правильно классифицирует реальные и сгенерированные сэмплы, а $G$ старается минимизировать эту вероятность:\n","\n","$$\\underset{G}{\\text{min}} \\underset{D}{\\text{max}}V(D,G) = \\mathbb{E}_{x\\sim p_{data}(x)}\\big[logD(x)\\big] + \\mathbb{E}_{z\\sim p_{z}(z)}\\big[log(1-D(G(x)))\\big]$$\n","\n","[Выясняется](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), что решение в этой минимаксной игре достигается при $p_g = p_d$ (и дискриминатор в этом случае может угадывать случайно). В реальности модели не всегда могут сойтись к этой точке.\n","\n","[DCGAN](https://arxiv.org/pdf/1511.06434.pdf) (Deep Convolutional GAN) называют GAN, который явно использует свёртки и транспонированные свёртки в дискриминаторе и генераторе соответственно. Откройте статью -- мы будем идти очень близко с авторами."]},{"cell_type":"markdown","metadata":{"id":"iYPV9p90wSgG","colab_type":"text"},"source":["## Датасет\n","Всем надоели цифры, поэтому обучаться мы будем на датасете CelebA ([Large-scale CelebFaces Attributes](Large-scale CelebFaces Attributes)). В датасете на каждую фотку есть её аттрибуты, но мы их пока использовать не будем.\n","\n","<img width='500px' src='http://mmlab.ie.cuhk.edu.hk/projects/celeba/overview.png'>\n","\n","Автор, когда готовил эту тетрадку, долго думал, как загрузить датасет, чтобы всем было удобно. Это оказалось трудно, потому что прямых ссылок на него нигде нет, и, соответственно, просто сделать `!wget ...` нельзя. По удачному стечению обстоятельств, неделю назад кто-то [добавил](https://github.com/pytorch/vision/blob/master/torchvision/datasets/celeba.py) скрипты для загрузки этого датасета в сам `torchvision`, но в `pip` новая версия за такой срок ещё не успела появиться, поэтому мы обновимся напрямую из репозитория на гитхабе:"]},{"cell_type":"code","metadata":{"id":"RjCn03H0Rimk","colab_type":"code","colab":{}},"source":["# модель будет обучаться долго - рекомендую сохранять промежуточные версии. В колабе это можно делать примерно так\n","from google.colab import drive\n","drive.mount('/content/drive')\n","#теперь для сохранения файлов вам доступна директория /content/drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"roFGEo3b37Wa","colab_type":"code","colab":{}},"source":["!pip install git+https://github.com/pytorch/vision.git"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7AF9qQ04b2k","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","from torchvision import transforms, datasets"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"raBYoUEjeXRm","colab_type":"code","colab":{}},"source":["device = torch.device('cuda:0')  # не забудьте включить GPU\n","\n","image_size = 64\n","batch_size = 64"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"__rYnOod4ded","colab_type":"code","colab":{}},"source":["transform=transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.CenterCrop(image_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","    # Normalize здесь приводит значения в промежуток [-1, 1]\n","])\n","\n","dataset = datasets.CelebA('data', download=True, transform=transform)\n","\n","loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BE8y2oIB_2N3","colab_type":"code","colab":{}},"source":["dataset[5][0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLSFZAaNe9NA","colab_type":"code","colab":{}},"source":["# посмотрите на данные (вы писали нужный код в колоризации)\n","# ..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hv2Jga9EPaeT","colab_type":"text"},"source":["## Модель\n","\n","Генератор $G$ преобразует латентный вектор $z$ в пространство данных (в нашем случае -- картинки 3x64x64). В статье используют последовательность блоков из транспонированных свёрток, BatchNorm-ов и ReLU. На выходе каждое значение лежит в [-1, 1] (мы делаем TanH), в соответствии с нормализацией, которую мы сделали раньше.\n","\n","<img width='600px' src='https://pytorch.org/tutorials/_images/dcgan_generator.png'>"]},{"cell_type":"code","metadata":{"id":"xUkaAeWKAYpX","colab_type":"code","colab":{}},"source":["device = torch.device('cuda:0')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3CuKv_Zi54ra","colab_type":"code","colab":{}},"source":["num_channels = 3\n","latent_size = 100\n","base_size = 64\n","\n","G = nn.Sequential(\n","    # input is Z, going into a convolution\n","    nn.ConvTranspose2d(latent_size, base_size * 8, 4, 1, 0, bias=False),\n","    nn.BatchNorm2d(base_size * 8),\n","    nn.ReLU(True),\n","    \n","    # (base_size*8) x 4 x 4\n","    nn.ConvTranspose2d(base_size * 8, base_size * 4, 4, 2, 1, bias=False),\n","    nn.BatchNorm2d(base_size * 4),\n","    nn.ReLU(True),\n","    \n","    # (base_size*4) x 8 x 8\n","    nn.ConvTranspose2d(base_size * 4, base_size * 2, 4, 2, 1, bias=False),\n","    nn.BatchNorm2d(base_size * 2),\n","    nn.ReLU(True),\n","    \n","    # (base_size*2) x 16 x 16\n","    nn.ConvTranspose2d(base_size * 2, base_size, 4, 2, 1, bias=False),\n","    nn.BatchNorm2d(base_size),\n","    nn.ReLU(True),\n","    \n","    # (base_size) x 32 x 32\n","    nn.ConvTranspose2d(base_size, num_channels, 4, 2, 1, bias=False),\n","    nn.Sigmoid()\n","    # (num_channels) x 64 x 64\n",").to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtv1uteaAcjZ","colab_type":"code","colab":{}},"source":["z = torch.randn(1, latent_size, 1, 1).to(device)\n","G(z)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-0c7SaZsidzx","colab_type":"text"},"source":["Дискриминатор -- это обычный бинарный классификатор. В статье он устроен симметрично генератору: Conv2d, BatchNorm, ReLU, Conv2d... Параметры сверток можно поставить в обратную сторону."]},{"cell_type":"code","metadata":{"id":"LZdLcZzviZlD","colab_type":"code","colab":{}},"source":["D = nn.Sequential(\n","    # ...\n","    nn.Conv2d(base_size * 8, 1, 4, 2, 0, bias=False),\n","    nn.BatchNorm2d(1),\n","    nn.Sigmoid()\n",").to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RF905ABD9cTG","colab_type":"code","colab":{}},"source":["z = torch.randn(1, num_channels, image_size, image_size).to(device)\n","D(z)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_cvC_RdKiMmS","colab_type":"text"},"source":["В статье акцентируют внимание на необходимость нестандартной инициализации весов."]},{"cell_type":"code","metadata":{"id":"JTR8nHzu77kZ","colab_type":"code","colab":{}},"source":["def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)\n","\n","\n","# apply рекурсивно применяет применяет функцию ко всем своим подмодулям\n","G.apply(weights_init)\n","D.apply(weights_init)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1NV6gwpojEv4","colab_type":"text"},"source":["## Обучение\n","\n","У GANов, помимо сходимости, есть проблема, что их непонятно, как сравнивать между собой, потому что у нас не один лосс, а два. Поэтому полезнее во время обучения смотреть на генерируемые картинки, а не цифры."]},{"cell_type":"code","metadata":{"id":"6Cl9e1eIR8P0","colab_type":"code","colab":{}},"source":["# если мы предварительно сохраняли модели и хотим запустить их, то это вот так\n","D.load_state_dict(torch.load('/content/drive/My Drive/D.pt')) # можно и другую директорию, но вот это прямо внутри вашего гугл диска\n","G.load_state_dict(torch.load('/content/drive/My Drive/G.pt'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YupLq8GaRRhL","colab":{}},"source":["num_epochs = 5\n","learning_rate = 1e-3\n","\n","img_list = []\n","G_losses = []\n","D_losses = []\n","iters = 0\n","\n","optim_G = # ваш любимый оптимизатор параметров дискриминатора\n","optim_D = # ваш любимый оптимизатор параметров генератора\n","  \n","for epoch in range(num_epochs):\n","    for (data, _) in loader:\n","        # Обучать GANы всегда долго, и мы хотим по максимуму переиспользовать вычисления\n","\n","        # 1. Обучим D: max log(D(x)) + log(1 - D(G(z)))\n","        \n","        D.zero_grad()\n","        \n","        # a) Распакуйте данные на нужный девайс\n","        #    Прогоните через сеть\n","        #    Сгенерируйте вектор из единичек (ответы для реальных сэмплов)\n","        #    Посчитайте лосс, сделайте .backward()\n","        # b) Посэмплите из torch.randn\n","        #    Прогоните этот шум через генератор\n","        #    detach-ните (нам не нужно считать градиенты G)\n","        #    Прогоните через дискриминатор\n","        #    Сгенерите вектор из нулей (ответы для фейков)\n","        #    Посчитайте лосс, сделайте backward (он сложится, а не перезапишется)\n","        #\n","        #    Также можно сначала сгенерировать данные, а потом собрать из двух частей батч,\n","        #    В котором первая половина лэйблов будет нулями, а вторая -- единицами\n","        \n","        optim_D.step()\n","        \n","\n","        # 2. Обучим G: max log(D(G(z)))\n","\n","        G.zero_grad()\n","        \n","        # Тут проще:\n","        #    Получим вектор неправильных ответов -- вектор единиц (мы ведь хотим, чтобы D считал их неправильными)\n","        #    Прогоним ранее сгенерированные картинки через D\n","        #    Посчитаем лосc, сделаем .backward()\n","        \n","        optim_G.step()\n","\n","        # Раз в сколько-то итераций логгируем лосс\n","        if iters % 10 == 0:\n","            # Выведем информацию о том, как наша сеть справляется\n","            print(f'{epoch}/{num_epochs}, {iters/len(loader)}')\n","            print(f'  G loss: {G_loss}')\n","            print(f'  D loss: {D_loss}')\n","            print()\n","            \n","        D_losses.append(D_loss.item())\n","        G_losses.append(G_loss.item())\n","\n","        if iters % 50 == 0:\n","            # вы на этом батче уже генерировали какие-то картинки: просто добавьте их в список\n","            \n","            # а вот тут сохраняем\n","            torch.save(D.state_dict(), '/content/drive/My Drive/D.pt')\n","            torch.save(G.state_dict(), '/content/drive/My Drive/G.pt')\n","        iters += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"53H3JFfJveS2","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10,5))\n","plt.plot(G_losses, label=\"G\")\n","plt.plot(D_losses, label=\"D\")\n","plt.xlabel(\"Iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jP4hziIekgfg","colab_type":"code","colab":{}},"source":["# распечатайте ваши картинки"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6kUdCbvsZgXq","colab_type":"text"},"source":["### Что дальше?\n","\n","Довольно старый, но актуальный список трюков: https://github.com/soumith/ganhacks\n","\n","Вообще, теория сходимости GANов очень сильно развилась за последнее время. Если хотите во всём этом разобраться, то возьмите какую-нибудь [достаточно новую статью](https://arxiv.org/pdf/1802.05957.pdf) и рекурсивно почитайте оттуда абстракты из списока литературы."]}]}