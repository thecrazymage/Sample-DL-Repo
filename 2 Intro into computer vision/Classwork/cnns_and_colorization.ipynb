{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnns_and_colorization.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"svYWx8G1lePZ","colab_type":"text"},"source":["# Свёрточные сети\n","\n","Сегодня мы детальнее поговорим про общие подходы при обучении нейросетей, и что происходит внутри них.\n","\n","<img width='400px' src='https://raw.githubusercontent.com/sslotin/universum-dl/43390d26d5f256dcc68a6ba51998bd626b3f6d33/images/cat.png'>\n","\n","Если попытаться визуализировать то, что выучивает каждый нейрон в нейросети (например, посмотрев, какие входные пиксели на него сильнее всего влияют), то можно увидеть, что чем глубже находится слой, тем более абстрактные фичи он содержит.\n","\n","Например, в сетях для распознавания картинок первые слои учатся обнаруживать геометрические примитивы: линии, границы, углы. Следующий слой может распознавать простые геометрические фигуры. Следующий распознаёт наличие целых объектов и т. д."]},{"cell_type":"markdown","metadata":{"id":"2YGzdiWilePg","colab_type":"text"},"source":["**Weight sharing**. [Эксперименты с дропаутом](https://arxiv.org/abs/1701.05369) показывают, что в линейном слое примерно 99% весов на самом деле можно выкинуть. Логично, что в оптимальной архитектуре не должно быть бесполезных весов — лишние параметры всегда ведут к переобучению. В случае с картинками решение в том, чтобы использовать информацию о расположении пикселей относительно друг друга."]},{"cell_type":"markdown","metadata":{"id":"A8JSCr9jlePj","colab_type":"text"},"source":["## Свёртки и пуллинги\n","\n","**Как хранятся картинки**. Когда говорят «изображение», представляйте не прямоугольник, а параллелепипед, высотой которого будет размер каналов. Например, обычные цветные RGB картинки имеют 3 канала: на красный (R), зелёный (G) и синий (B).\n","\n","0. Введем такую функцию, как **ядро** (англ. **kernel**) — она считает скалярное произведение вектора-входа со своим вектором-параметром.\n","1. Разобьем исходный паралеллелепипед на сколько-то параллелепипедов одинакового размера вдоль размерности, соответствующей каналам. Они могут пересекаться.\n","2. Каждый из них «разгладим» в вектор.\n","3. К кажому такому вектору и применим по очереди каждый кернел (их обычно берут много разных).\n","4. Положим то, что получилось, в новый параллелепипед.\n","5. Посчитаем для кажой ячейки какую-нибудь нелинейность. Обычно это ReLU из-за вычислительных причин.\n","\n","<img width='350px' src='https://raw.githubusercontent.com/sslotin/universum-dl/43390d26d5f256dcc68a6ba51998bd626b3f6d33/images/conv1.png'>\n","\n","Эта операция называется **свёрткой**. Помимо кернела, в ней есть другие параметры — паддинг (отступ по краям), страйды (шаги по x и y). Также свёртка может быть в 2d и 3d. Посмотрите этот репозиторий, чтобы получше разобраться со свёрточной арифметикой: https://github.com/vdumoulin/conv_arithmetic\n","\n","![](http://deeplearning.net/software/theano/_images/numerical_padding_strides.gif)\n","\n","**Пулингом** называют операцию, при которой входной тензор так же разбивается на квадраты (не паралепипеды — операция независима по каждому каналу) и на каждом квадрате считается какая-нибудь редукция (чаще всего максимум или среднее по всем значениям в квадрате), после чего полученные значения записываются на следующий слой в том же порядке.\n","\n","<img width='400px' src='http://cs231n.github.io/assets/cnn/maxpool.jpeg'>\n","\n","В свёртках переиспользуется очень много параметров: кернел для каждого фильтра (выходного канала) использует один и тот же вектор-параметр для скалярного умножения. Из-за этого каждый фильтр как правило выучивает какую-то конкретную фичу, вроде наличия какого-либо объекта на своём регионе. Пулинг используют затем для понижения размерности: каждый нейрон после свертки выражает степень уверенности, что на регионе присутствует какой-то объект, и поэтому логично в качестве вероятности наличия объекта на регионе из под-регионов использовать максимум или среднее.\n","\n","Чаще всего используют свёртки 3x3 со страйдом 2x2 (то есть квадраты перекрываются по 3 крайним пикселям) с пулингом размера 2x2 (не перекрываются)."]},{"cell_type":"markdown","metadata":{"id":"sIfUCzR0lePp","colab_type":"text"},"source":["## Аугментация данных\n","\n","Аугментацией называется процесс получения новых синтетических данных из имеющихся, чтобы подать в обучение. Это часто (особенно в компьютерном зрении) позволяет улучшить качество модели, не используя дополнительных данных.\n","\n","Формально, в случае с классификацией, аугментация — это любое преобразование, которое корректно изменяет данные, не меняя их класс.\n","\n","В случае с картинками, можно попробовать добавить следующие преобразования, которые с какой-то вероятностью будут использоваться во время обучения:\n","\n","* Поворот на малый угол.\n","* Добавление шума.\n","* Обрезание границ и последующее растяжение до исходного размера.\n","* Горизонтальное отражение (но в нашем случае оно вредно).\n","* Смещение на небольшое расстояние.\n","\n","Понятно, что лейбл эти преобразования изменить не должны.\n","\n","<img src='https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/a5da2c3b4174449d13dd746b7d00897c6bc1f334/5-Figure2-1.png' width='500px'>"]},{"cell_type":"markdown","metadata":{"id":"tGVT5oqzlePr","colab_type":"text"},"source":["## Взрывающийся градиент\n","\n","В сетях происходит очень много чего стохастического: батч формируется случайно, аугментация, рандомизированные слои вроде дропаута, вычислительные ошибки. Это всё может привести к тому, что сеть на какой-то итерации будет очень уверенна в неправильном предсказании и некоторые её параметры получат очень большой градиент. Это может привести к тому, что эти параметры «улетят» куда-то настолько далеко, и после этого сеть будет всегда предсказывать класс, который на этой итерации был правильным. \n","\n","Простое решение: просто обрезать градиент в случае, если градиент больше какого-то фиксированного значения. Для этого есть функция `torch.nn.utils.clip_grad_norm_`, которая принимает параметры модели и параметр `threshold`. Она считает норму (длину вектора) градиента и, если она больше `threshold`, нормирует градиенты так, чтобы она была равна `threshold`. Эта функция также возвращает само значение нормы, что может быть очень полезно при анализе обучения (например, если она становится маленькой, то, значит, сеть сходится к какому-то плато)."]},{"cell_type":"markdown","metadata":{"id":"COWp1WKclePu","colab_type":"text"},"source":["## Инициализация параметров\n","\n","Сначала приведем пример плохой инициализации. Пусть мы задали все значения изначально нулями. В таком случае наша модель становится эквивалентна линейной модели — производная по функции потерь одинакова для каждого $w_i$, таким образом, все веса имеют одинаковые значения и в последующей итерации, что делает нейроны в сети симметричными.\n","\n","Подход получше — инициализировать каждый вес случайно. Но тут нужно быть осторожным — если задать их слишком большими, то сеть может быть изначально очень уверенна в своих предсказаниях, и подвинуть параметры оттуда будет очень трудно.\n","\n","Решение следующее. С точки зрения слоя, ему на вход подается сэмпл из какого-то распределения, и он под это распределение подстраивается. В нейросетях размеры слоев достаточно большие, чтобы в них работали законы статистики, все разработчики фреймворках условились инициализировать веса всех слоев в предположении, что на вход подаются данные из какого-то распределения со средним 0 и дисперсией 1, и на выходе должно получиться какое-то распределение со средним тоже 0 и дисперсией 1. Чаще всего изначальные веса берут либо из нормального, либо из равномерного распределения, «обрезанного» так, чтобы дисперсия каждого выходного значения получилась единичной.\n","\n","Аналогично нужно поступать со входными векторными данными: нормализовывать. Это будет важно при работе с изображениями: не надо подавать на вход вектора с элементами от 0 до 255. Самое простое рабочее решение — нормализовать вход, поделив его на 255."]},{"cell_type":"markdown","metadata":{"id":"-v2sSq0elePy","colab_type":"text"},"source":["## Минутка физики\n","\n","Потребляемая энергия в сети с переменным током в единицу времени считается по формуле\n","\n","$$W = CV^2f$$\n","\n","где $C$ означает емкость сети, $V$ означает напряжение, а $f$ — частоту. В случае с процессорами, это именно та частота, с которой выполняются элементарные операции, например сложение.\n","\n","<img width='350px' src='https://i.ibb.co/yhsGRJK/Screenshot-from-2019-02-08-14-52-07.png'>\n","\n","Однако, если мы сделаем сеть из двух параллельно подключенных процессоров, работающих на половинной частоте, мы можем получить сеть, потребляющую ~40% изначальной энергии, делающую то же количество полезной работы — то же суммарное количество процессорных тактов:\n","\n","<img width='450px' src='https://i.ibb.co/WgLCxxL/Screenshot-from-2019-02-08-14-52-18.png'>\n","\n","Поэтому для хорошо распараллеливаемых операций используют другой тип вычислительных устройств, в которых не 4-8 быстрых (3-4 GHz) процессоров, а несколько тысяч медленных (~1GHz)."]},{"cell_type":"markdown","metadata":{"id":"eFLKQB7IleP1","colab_type":"text"},"source":["## Device-agnostic код\n","\n","К любой модели или тензору в PyTorch можно применить `.cuda()` и `.cpu()`, чтобы перевести тензор на память GPU или в оперативную память соответственно. Но если мы будем писать такой код, нам будет довольно проблематично портировать его на другие машины, где, например, нет GPU (например, если вы хотите скачать тетрадку с colab к себе и запустить).\n","\n","Многие фреймворки позволяют абстрагироваться от устройства конкретных вычислительных устройств. В PyTorch для этого есть объект `torch.device`, который позволяет явно задавать, на каком устройстве хранить тензор или модель."]},{"cell_type":"code","metadata":{"id":"1EWLdWGFleP4","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","\n","device = torch.device('cuda:0')  # используй первую GPU (номеруются с нуля)\n","\n","X = torch.randn(5, 100, device=device)  # создай матрицу на этом устройстве\n","# альтернативно: X = X.to(device)\n","\n","# создадим какую-нибудь модель\n","model = nn.Sequential(\n","    nn.Linear(100, 20),\n","    nn.ReLU(),\n","    nn.Linear(20, 8)\n",")\n","\n","model = model.to(device)  # переведи параметры модели на это устройство\n","\n","model(X)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LRfKGXKGleQA","colab_type":"text"},"source":["# Колоризация изображений\n","\n","Начнём практическую часть. Обучим autoencoder-like сеть, которая учится восстанавливать изображение по его черно-белой версии. В качестве лосса будем так же использовать какую-нибудь меру расстояния между изображениями (например, l1 или l2).\n","\n","Тот пайплайн, что у нас получится, с минимальными изменениями можно будет также использовать и для других подобных задач, связанных с восстановлением изображений после каких-либо необратимых преобразований, например после подмешивании шума (denoising autoencoder) или понижения размера (DeepHD).\n","\n","![](https://camo.githubusercontent.com/c5f95c94d70a3e52561c1d0591e84a5e3b86eb74/687474703a2f2f726963687a68616e672e6769746875622e696f2f636f6c6f72697a6174696f6e2f7265736f75726365732f696d616765732f6e65745f6469616772616d2e6a7067)"]},{"cell_type":"code","metadata":{"id":"3TMZ8ypgleQE","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"isyXUmOoleQM","colab_type":"text"},"source":["Для начала скачаем данные. Годятся вообще любые изображения, не обязательно из какого-то изветсного датасета. Этой командой можно скачать и распакавать фотографии с одной школы по программированию, проходившей этим летом."]},{"cell_type":"code","metadata":{"id":"tz3QJKqsleQO","colab_type":"code","colab":{}},"source":["!wget http://sereja.me/f/universum_compressed.tar\n","!tar xf universum_compressed.tar"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jO34pEQmleQV","colab_type":"text"},"source":["Есть два подхода к работе с данными:\n","\n","1. Сначала преобразовать все имеющиеся данные к виду, который принимает нейросеть (сразу к тензорам одинакового размера).\n","2. Хранить сырые данные и преобразование препроцессинга (функцию) и собирать батчи на лету.\n","\n","Если это не что-то совсем простое, то второй вариант предпочтительнее, так как он не требует дополнительной памяти (датасеты могут быть большими), времени на векторизацию датасета, а так же сбор батча «на лету» позволяет там же делать аугментацию.\n","\n","Для этого в PyTorch есть две абстракции: `Dataset` и `DataLoader`.\n","\n","`Dataset` — абстрактный класс, от которого нужно отнаследовать класс датасета, который мы напишем. В нём должны быть определён конструктор (в нём обычно загружаются в память сырые данные, которые лежат где-то на диске, а также сохраняется какая-нибудь другая информация), метод `__len__` (должен вернуть размер датасета) и `__getitem__`, который должен по номеру сэмпла вернуть его в виде тензора (возможно, произведя какой-нибудь препроцессинг)."]},{"cell_type":"code","metadata":{"id":"xfamcDfslqjA","colab_type":"code","colab":{}},"source":["# tqdm -- это маленькая библиотечка для прорисовывания progress bar-ов прямо в питоне\n","\n","from tqdm import tqdm\n","from time import sleep\n","\n","for i in tqdm(range(10)):\n","    sleep(0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQGNRnBpleQb","colab_type":"code","colab":{}},"source":["import os\n","from PIL import Image\n","\n","class ColorizationDataset(Dataset):\n","    def __init__(self, path, transform_x, transform_y):\n","        self.transform_x = transform_x\n","        self.transform_y = transform_y\n","      \n","        filenames = []\n","        for root, dirs, files in os.walk(path):\n","            for file in files:\n","                if file.endswith('.jpg') or file.endswith('.JPG'):\n","                    filenames.append(os.path.join(root, file))\n","\n","        self.images = []\n","        for filename in tqdm(filenames):\n","            try:\n","                with Image.open(filename) as image:\n","                    self.images.append(image.copy())\n","            except:\n","                pass\n","                #print('Could not load image:', filename)\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img = self.images[idx]\n","        Y = self.transform_y(img)\n","        X = self.transform_x(Y)\n","        return X, Y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bR8CNjjjleQj","colab_type":"text"},"source":["Чтобы подавать картинки на вход нейросети, нужно их перевести в тензоры, причём одинакового размера."]},{"cell_type":"code","metadata":{"id":"FNSJsAk4leQn","colab_type":"code","colab":{}},"source":["transform_all = transforms.Compose([\n","    # вырежем случайный квадратик\n","    transforms.RandomResizedCrop(128),\n","    # горизонтально перевернем -- изображение останется валидным\n","    transforms.RandomHorizontalFlip(),\n","    # что бы ещё поделать, чтобы увеличить размер датасета?\n","    # ...\n","    transforms.ToTensor(),\n","])\n","\n","def to_grayscale(x):\n","    return 1 - (x[0] * 0.299 + x[1] * 0.587 + x[2] * 0.114).view(1, 128, 128)\n","    # минутка эволюционной биологии: как вы думаете, почему коэффициенты именно такие?"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8EhPdNBGleQt","colab_type":"text"},"source":["Здесь `transform_all` и `to_grayscale` являются функциями (формально, первый является функтором), которые мы передадим дальше в `DataLoader`, который оборачивает датасет и позволяет итерироваться по нему по батчам, а также реализует разные полезные функции вроде перемешивания данных после каждой эпохи."]},{"cell_type":"code","metadata":{"id":"YXNkMfkGleQx","colab_type":"code","colab":{}},"source":["dataset = ColorizationDataset('universum-photos', to_grayscale, transform_all)\n","loader = DataLoader(dataset, batch_size=64, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZMwOUGB8leQ9","colab_type":"text"},"source":["**Skip-connection**. Иногда бывает полезно присоединить к выходу какого-то слоя его вход, чтобы следующий получил такую же, неизменённую копию. Здесь мы поступим именно так: подадим исходное черно-белое изображение в какую-то одну часть сети, которая сконцентрируется на определении цвета, а затем припишем последним слоем её выход и отправим дальше другому модулю, который уже раскрасит это исходное изображение. От простоты `nn.Sequential`, правда, уже придётся отказаться, и нужно написать свой класс."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"K_pr_KE4UmXE","colab":{}},"source":["class Colorizer(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        \n","        self.preconcat = nn.Sequential(\n","            nn.Conv2d(1, 32, (3, 3), padding=1), # по дефолту stride = 1, а следовательно размерность не меняется\n","                                                 # меняем мы только количество каналов\n","            nn.MaxPool2d((2, 2), stride=(2, 2)), # а вот тут мы уменьшаем и высоту, и ширину, в два раза\n","            nn.ReLU(),\n","            # ...\n","            # много-много таких штук ещё сделайте\n","            # ...\n","            nn.Upsample(scale_factor=2),         # увеличиваем высоту и ширину в два раза\n","            nn.Conv2d(256, 128, (3, 3), padding=1),\n","            nn.ReLU(),\n","            \n","            # ...\n","            # много-много таких же, но наоборот\n","            # ...\n","        )\n","         \n","        self.postconcat = nn.Sequential(         # эту сетку можно особо не увеличивать - она не должна быть очень умной\n","            nn.Conv2d(65, 32, (3, 3), padding=1),# подумайте, откуда у автора тут 65\n","            nn.ReLU(),\n","            nn.Conv2d(32, 3, (3, 3), padding=1),\n","            nn.Sigmoid()\n","        )\n","    \n","    def forward(self, x):\n","        h = self.preconcat(x)\n","        # исходное чб изображение -- просто дополнительным слоем\n","        h = torch.cat((h, x), 1)\n","        h = self.postconcat(h)\n","        return h"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ql85BQRNleRG","colab_type":"text"},"source":["Глубокие сети очень часто состоят из повторяющихся блоков, отличающихся только размерностью (в данном случае — количеством фильтров). Чтобы сократить количество кода и уменьшить вероятность багов, блоки можно обернуть в одну функцию, возвращающую мини-модель из нескольких слоев.\n","\n","Концептуальный пример:"]},{"cell_type":"code","metadata":{"id":"IIf2JUzvleRK","colab_type":"code","colab":{}},"source":["def Block(channels_in, channels_out):\n","    return nn.Sequential(\n","        nn.Conv2d(channels_in, channels_out, (3, 3), padding=1),\n","        # nn.MaxPool2d(),\n","        # nn.Dropout(),\n","        # nn.ReLU(),\n","        # nn.BatchNorm(),\n","    )\n","\n","model = nn.Sequential(\n","    Block(3, 64),\n","    nn.MaxPool2d((2, 2)),\n","    Block(64, 128),\n","    nn.MaxPool2d((2, 2)),\n","    Block(128, 256),\n","    Block(256, 256),\n","    Block(256, 256),\n","    nn.Upsample(),\n","    Block(256, 128),\n","    nn.Upsample(),\n","    Block(128, 64),\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jkR1-2rOleRP","colab_type":"text"},"source":["Дальше как обычно:"]},{"cell_type":"code","metadata":{"id":"WUK0eH0ZleRS","colab_type":"code","colab":{}},"source":["num_epochs = 5\n","lr = 1e-3\n","\n","model = Colorizer()#.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","criterion = nn.L1Loss()  # тут можно поиграться с лоссами"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YhDXCo2CleRc","colab_type":"code","colab":{}},"source":["history = []\n","for epoch in range(num_epochs):\n","    for x, y in loader:\n","        # теперь сами:\n","        # 0. распакавать данные на нужное устройство\n","        # 1. сбросить градиент\n","        # 2. прогнать данные через сеть\n","        # 3. посчитать loss\n","        # 4. залоггировать его куда-нибудь\n","        # 5. сделать .backward()\n","        # 6. optimizer.step()\n","        # (7. вывести пример колоризации -- см код ниже)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hSNIw5CbleRf","colab_type":"text"},"source":["В подобных нечётко поставленных задачах важно смотреть не цифры, а на реальные примеры.\n"]},{"cell_type":"code","metadata":{"id":"ErhISBCbnk58","colab_type":"code","colab":{}},"source":["def to_numpy_image(img):\n","    # tl;dr: PyTorch хочет (3, 128, 128), а plt.imshow хочет (128, 128, 3)\n","    # есть два популярных формата для цветных картинок:\n","    #  1. где размерность, соответствующая каналам, идёт последней\n","    #  2. где размерность, соответствующая каналам, идёт первой\n","    # при работе с нейросетями удобен первый подход -- так запрашиваемая\n","    # при вычислениях память идёт последовательно, и из-за кэширования\n","    # операции свёртки работают быстрее\n","    # второй подход удобнее при уже работе с устройством, которое эти картинки показывает\n","    # -- удобно на три лампочки послать сразу три последовательно идущих байта\n","    return img.detach().cpu().view(3, 128, 128).transpose(0, 1).transpose(1, 2).numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"2AASI8egleRh","colab_type":"code","colab":{}},"source":["for t in range(10):\n","    img_gray, img_true = dataset[t]\n","    img_pred = model(img_gray.to(device).view(1, 1, 128, 128))\n","    img_pred = to_numpy_image(img_pred)\n","    # теперь это numpy-евский ndarray размера (128, 128, 3)\n","    plt.figure(figsize=(10,10))\n","    \n","    plt.subplot(141)\n","    plt.axis('off')\n","    plt.set_cmap('Greys')\n","    plt.imshow(img_gray.reshape((128, 128)))\n","\n","    plt.subplot(142)\n","    plt.axis('off')\n","    plt.imshow(img_pred.reshape((128, 128, 3)))\n","\n","    plt.subplot(143)\n","    plt.axis('off')\n","    plt.imshow(to_numpy_image(img_true))\n","    \n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iR-twB6-leRs","colab_type":"text"},"source":["## *Тизер: adversarial loss\n","\n","У нашего подхода к колоризации есть одна весьма существенная проблема: непонятно, как определять функцию потерь. Выясняется, что l1 или l2 в некоторых случаях даже являются принципиально неправильным выбором. Представьте, что у нас есть датасет фотографий с летнего лагеря, в котором все люди ходят в футболках двух разных цветов — например, красного и синего — интенсивность которых одинакова и неотличима на черно-белых версиях. Тогда наш лосс заставит сеть выбирать что-то «по середине» (в случае с l2 это будет среднее, а с l1 медиана), и, скорее всего, она сгенерирует что-то серое, в то время как она должна с какой-то вероятностью сгенерировать явно красную или явно синюю футболку.\n","\n","Решение в следующем: выход (колоризованное изображение) кормить в другую сеть, которая учится определять «правдоподобность» раскраски. Помимо восстановления изображения с точки зрения какой-то меры близости, сети-генератору (колоризатору) нужно ещё и обмануть сеть-дискриминатор, а сети-дискриминатору нужно наоборот, учиться отличать настоящую колоризацию от нашей.\n","\n","Подобные схемы с двумя состязяющимися сетями называют GAN-ам (Generative Adversarial Networks), о которых мы поговорим через занятие."]}]}